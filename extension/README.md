App URL Crawler (MV3)

Краткая инструкция (P0):

- Откройте Chrome/Edge → chrome://extensions → Включите режим разработчика → Загрузить распакованное → выберите папку `extension`.
- Перейдите на страницу целевого приложения.
- Нажмите на иконку расширения → в popup нажмите «Start».
- Расширение начнет слушать DOM/SPA‑переходы и webNavigation для текущей вкладки и собирать URL.
- Кнопки: Pause (пауза), Rescan (повторное извлечение ссылок со страницы), Reset (очистить список URL для приложения), Copy/JSON/CSV (экспорт текущего списка).

Ограничения P0/P1:

- Хранилище: IndexedDB (MV3 SW), лимит зависит от профиля; добавлено permission `unlimitedStorage`.
- Классификация: page/api/asset (простые эвристики, ассеты по расширениям).
- Сканер не выполняет «кликабельный» BFS по всем страницам — собирает ссылки из текущей вкладки и её SPA‑навигаций.
- Глубокий режим сети (fetch/XHR) и DevTools‑HAR отсутствуют в P0.

Структура:

- manifest.json — MV3 манифест.
- background/ — сервис‑воркер, оркестрация и хранение.
- content/ — контент‑скрипт: DOM‑сканер, SPA‑хуки History/Navigation API.
- ui/ — popup (список приложений/URL, фильтры, экспорт).
  - sidepanel.html, sidepanel.js — полноценная боковая панель с лайв‑обновлением.

Что добавлено в P1:

- IndexedDB: stores `apps`, `urls` с индексом (appId, canonicalHref) для дедупликации.
- Нормализация: сортировка query‑параметров; обрезка index.html; lowercased host; дефолтные порты.
- Лимиты: `maxUrls` (по умолчанию 1000) — при достижении активный скан для приложения приостанавливается.

Что добавлено в P2 (часть):

- Deep mode (опционально): перехват `fetch`/`XMLHttpRequest` в content‑script.
  - Сохраняем только URL, метод и код ответа (без тела запросов/ответов).
  - Включается чекбоксом «deep» в popup; действует на активную вкладку/приложение.
 - Side panel: отдельная панель со списком и контролами; открывается кнопкой «Side» в popup (Chrome) или через боковую панель (Firefox). Имеет автоматическое обновление при поступлении новых URL.

Overlay (встроенная кнопка на странице)
- Вкладка с инжектированным content‑script показывает мини‑панель внизу слева: «Crawler On/Off», «deep», «Rescan».
- Позволяет запустить/поставить на паузу сбор прямо со страницы, включить deep‑режим и форсировать разовый сбор DOM.
- Панель появляется при первой инъекции скрипта (например, после нажатия Start в popup или запуска BFS).
- Скриншот можно положить в `docs/overlay.png` и сослаться в README по желанию.

Настройки в боковой панели (per‑app):

- Ignore hash: убирать фрагмент `#...` из URL при каноникализации.
- Include assets: учитывать статические ассеты (по умолчанию выключено).
- Max URLs: лимит записей для приложения (0 = без лимита). При достижении — авто‑пауза.
- Query params: режим нормализации query‑строки для дедупликации: Sort (сортировать параметры) или As‑is (оставлять как есть).

Обход (BFS)
- В сайд‑панели: блок Crawler (BFS) — задайте глубину (Depth) и скорость (Rate, мс), затем Start/Pause/Stop.
- Работает в одном табе: переходит по очереди страниц (только kind=page) в пределах скоупа приложения.
- После каждой навигации ждёт короткое окно сбора ссылок и двигается дальше (rateMs).
- Собранные URL как и раньше идут в базу с дедупликацией.

Авторство
- Реализация/идея: @lamerzen via privesc.ru
